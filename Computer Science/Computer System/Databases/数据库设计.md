## 设计模式

### E-R模型

实体（Entity）:客观存在并可相互区别的事物称为实体

联系（Relationship）:一个实体内部的联系指组成实体的各属性之间的联系，而实体间的联系指不同实体之间的相互关联

### 数据库设计

**1.数据库表设计**

1. 尽量控制单表数据量的大小，建议控制在 500 万以内。500 万并不是 MySQL 数据库的限制，过大会造成修改表结构、备份、恢复都会有很大的问题，可以用历史数据归档（应用于日志数据），分库分表（应用于业务数据）等手段来控制数据量大小；
2. 谨慎使用 MySQL 分区表。分区表在物理上表现为多个文件，在逻辑上表现为一个表谨慎选择分区键，跨分区查询效率可能更低建议采用物理分表的方式管理大数据；
3. 禁止在数据库中存储图片，文件等大的二进制数据。通常文件很大，会短时间内造成数据量快速增长，数据库进行数据库读取时，通常会进行大量的随机 IO 操作，文件很大时，IO 操作很耗时 通常存储于文件服务器，数据库只存储文件地址信息；
4. 禁止在线上做数据库压力测试。

**2.数据库字段设计**

1. 优先选择符合存储需要的最小的数据类型。列的字段越大，建立索引时所需要的空间也就越大，这样一页中所能存储的索引节点的数量也就越少也越少，在遍历时所需要的 IO 次数也就越多， 索引的性能也就越差；
2. 避免使用 TEXT、BLOB 数据类型，最常见的 TEXT 类型可以存储 64k 的数据；
3. 尽可能把所有列定义为 NOT NULL。

**3.数据库索引设计**

1. 限制每张表上的索引数量，建议单张表索引不超过 5 个；
2. 禁止给表中的每一列都建立单独的索引；
3. 每个 InnoDB 表必须有个主键；
4. 建立索引的目的是：希望通过索引进行数据查找，减少随机 IO，增加查询性能 ，索引能过滤出越少的数据，则从磁盘中读入的数据也就越少。区分度最高的放在联合索引的最左侧（区分度 = 列中不同值的数量 / 列的总行数）。尽量把字段长度小的列放在联合索引的最左侧（因为字段长度越小，一页能存储的数据量越大，IO 性能也就越好）。使用最频繁的列放到联合索引的左侧（这样可以比较少的建立一些索引）。

### 关系模式

第一范式（1NF）

该范式是为了排除重复组的出现，因此要求数据库的每个列的值域都由原子值组成；每个字段的值都只能是单一值。1971 年埃德加·科德提出了第一范式。即表中所有字段都是不可再分的。解决方案：想要消除重复组的话，只要把每笔记录都转化为单一记录即可。

第二范式（2NF）

表中必须存在业务主键，并且非主键依赖于全部业务主键。解决方案：拆分将依赖的字段单独成表。

第三范式（3NF）

表中的非主键列之间不能相互依赖，将不与 PK 形成依赖关系的字段直接提出单独成表即可。

## 存储结构

### 计算机的三级存储体系

根据存储介质的速度和成本，形成三级存储：层次越高，价格越贵，速度越快。

一级存储为易失性存储，二、三级存储都是非易失性存储

数据库实现比较复杂，数据保存在磁盘上，而为了提高性能，每次又可以把部分数据读入内存来计算，因为我们知道访问磁盘的成本大概是访问内存的十万倍左右，所以简单的搜索树难以满足复杂的应用场景。

### 数据库磁盘读取

磁盘读取数据靠的是机械运动，每次读取数据花费的时间可以分为寻道时间、旋转延迟、传输时间三个部分，寻道时间指的是磁臂移动到指定磁道所需要的时间，主流磁盘一般在5ms以下；旋转延迟就是我们经常听说的磁盘转速，比如一个磁盘7200转，表示每分钟能转7200次，也就是说1秒钟能转120次，旋转延迟就是1/120/2 = 4.17ms；传输时间指的是从磁盘读出或将数据写入磁盘的时间，一般在零点几毫秒，相对于前两个时间可以忽略不计。

考虑到磁盘IO是非常高昂的操作，计算机操作系统做了一些优化，当一次IO时，不光把当前磁盘地址的数据，而是把相邻的数据也都读取到内存缓冲区内，因为局部预读性原理告诉我们，当计算机访问一个地址的数据的时候，与其相邻的数据也会很快被访问到。每一次IO读取的数据我们称之为一页(page)。具体一页有多大数据跟操作系统有关，一般为4k或8k，也就是我们读取一页内的数据时候，实际上才发生了一次IO。

### 记录组织

文件中组织记录的常用方法有：

堆文件组织、顺序文件组织、多表聚集文件组织、B+树文件组织、散列(hashing)文件组织。

堆文件组织：文件中的记录没有顺序，是堆积起来的。

顺序文件组织：文件中的记录按搜索码值有序。磁盘块内的记录有序，且通过指针将磁盘块逻辑上有序地链接起来。

多表聚集文件组织：在一个块中存储多个关系的相关记录

## 数据库索引

索引是关系数据库中对某一列或多个列的值进行预排序的数据结构。通过使用索引，可以让数据库系统不必扫描整个表，而是直接定位到符合条件的记录，这样就大大加快了查询速度。

聚集索引：索引文件本身就是数据文件

非聚集索引：索引文件存储实际数据的地址

### B+树索引

B+树结构：所有结点的结构都相同，每个结点最多有n-1个搜索码值K1, K2, …, Kn-1，以及n个指针P1, P2, …, Pn，每个结点中的搜索码值升序存放。每个非叶结点有⌈n/2⌉到n个孩子结点(根结点除外)，叶结点依次链接起来

B+树文件组织： 叶结点组织文件记录，非叶结点起索引作用。真实的数据存在于叶子节点，非叶子节点不存储真实的数据，只存储指引搜索方向的数据项

![b+树](https://i.loli.net/2021/08/02/Nd67HDWP2BAlMge.jpg)

B+树索引性质

IO次数取决于b+数的高度h，假设当前数据表的数据为N，每个磁盘块的数据项的数量是m，则有h=㏒(m+1)N，当数据量N一定的情况下，m越大，h越小；而m = 磁盘块的大小 / 数据项的大小，磁盘块的大小也就是一个数据页的大小，是固定的，如果数据项占的空间越小，数据项的数量越多，树的高度越低。这就是为什么每个数据项，即索引字段要尽量的小，比如int占4字节，要比bigint8字节少一半。这也是为什么b+树要求把真实的数据放到叶子节点而不是内层节点，一旦放到内层节点，磁盘块的数据项会大幅度下降，导致树增高。当数据项等于1时将会退化成线性表。

当b+树的数据项是复合的数据结构，比如(name,age,sex)的时候，b+数是按照从左到右的顺序来建立搜索树的，比如当(张三,20,F)这样的数据来检索的时候，b+树会优先比较name来确定下一步的所搜方向，如果name相同再依次比较age和sex，最后得到检索的数据；但当(20,F)这样的没有name的数据来的时候，b+树就不知道下一步该查哪个节点，因为建立搜索树的时候name就是第一个比较因子，必须要先根据name来搜索才能知道下一步去哪里查询。比如当(张三,F)这样的数据来检索时，b+树可以用name来指定搜索方向，但下一个字段age的缺失，所以只能把名字等于张三的数据都找到，然后再匹配性别是F的数据了， 这个是非常重要的性质，即索引的最左匹配特性

### 散列索引

散列索引是采用一定的哈希算法，把键值换算成新的哈希值，检索时不需要类似B+树那样从根节点到叶子节点逐级查找，只需一次哈希算法即可立刻定位到相应的位置，速度非常快。

![img](https://img-blog.csdn.net/20170104204929966)

1.Hash 索引仅仅能满足"=","IN"和"<=>"查询，不能使用范围查询。
由于 Hash 索引比较的是进行 Hash 运算之后的 Hash 值，所以它只能用于等值的过滤，不能用于基于范围的过滤，因为经过相应的 Hash 算法处理之后的 Hash 值的大小关系，并不能保证和Hash运算前完全一样。
2.Hash 索引无法被用来避免数据的排序操作。
由于 Hash 索引中存放的是经过 Hash 计算之后的 Hash 值，而且Hash值的大小关系并不一定和 Hash 运算前的键值完全一样，所以数据库无法利用索引的数据来避免任何排序运算；
3.Hash 索引不能利用部分索引键查询。
对于组合索引，Hash 索引在计算 Hash 值的时候是组合索引键合并后再一起计算 Hash 值，而不是单独计算 Hash 值，所以通过组合索引的前面一个或几个索引键进行查询的时候，Hash 索引也无法被利用。
4.Hash 索引在任何时候都不能避免表扫描。
前面已经知道，Hash 索引是将索引键通过 Hash 运算之后，将 Hash运算结果的 Hash 值和所对应的行指针信息存放于一个 Hash 表中，由于不同索引键存在相同 Hash 值，所以即使取满足某个 Hash 键值的数据的记录条数，也无法从 Hash 索引中直接完成查询，还是要通过访问表中的实际数据进行相应的比较，并得到相应的结果。
5.Hash 索引遇到大量Hash值相等的情况后性能并不一定就会比B-Tree索引高。
对于选择性比较低的索引键，如果创建 Hash 索引，那么将会存在大量记录指针信息存于同一个 Hash 值相关联。这样要定位某一条记录时就会非常麻烦，会浪费多次表数据的访问，而造成整体性能低下

### 建索引原则

1.最左前缀匹配原则，非常重要的原则，mysql会一直向右匹配直到遇到范围查询(>、<、between、like)就停止匹配，比如a = 1 and b = 2 and c > 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。

2.=和in可以乱序，比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式。

3.尽量选择区分度高的列作为索引，区分度的公式是count(distinct col)/count(*)，表示字段不重复的比例，比例越大我们扫描的记录数越少，唯一键的区分度是1，而一些状态、性别字段可能在大数据面前区分度就是0，那可能有人会问，这个比例有什么经验值吗？使用场景不同，这个值也很难确定，一般需要join的字段我们都要求是0.1以上，即平均1条扫描10条记录。

4.索引列不能参与计算，保持列“干净”，比如from_unixtime(create_time) = ’2014-05-29’就不能使用到索引，原因很简单，b+树中存的都是数据表中的字段值，但进行检索时，需要把所有元素都应用函数才能比较，显然成本太大。所以语句应该写成create_time = unix_timestamp(’2014-05-29’)。

5.尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可。

## 数据库锁机制

乐观锁一般是指用户自己实现的一种锁机制，假设认为数据一般情况下不会造成冲突，所以在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测，如果发现冲突了，则让返回用户错误的信息，让用户决定如何去做。乐观锁的实现方式一般包括使用版本号和时间戳。

悲观锁一般就是我们通常说的数据库锁机制，悲观锁主要分为表锁、行锁、页锁。

### 表锁

表级锁会直接锁定整张表。表级锁是MySQL各存储引擎中最大颗粒度的锁定机制。

表锁的优点：实现逻辑简单、获取锁和释放锁的速度很快、避免死锁问题

表锁的缺点：争用锁定资源的概率高，致使并发度大大降低

表锁分类：表锁分为读锁和写锁，读锁不会阻塞其他用户对同一表的读请求，但会阻塞对同一表的写请求；写锁会阻塞其他用户对同一表的读和写操作

表锁优化：尽可能让锁定的时间变短，让可能并发进行的操作尽可能的并发。

### 行锁

行级锁仅对指定的记录加锁，也是目前各大数据库管理软件所实现的锁定颗粒度最小的。

行锁的优点：发生争用锁定资源的概率小，能尽可能大的提高数据库的并发处理能力从而提高高并发应用系统的性能

行锁的缺点：每次获取锁和释放锁需要做的事情多，资源消耗大，容易发生死锁

行锁分类：行锁分为共享锁、排他锁和更新锁

共享锁：当一个事务执行select语句时，数据库系统会为这个事务分配一把共享锁，来锁定被查询的数据。在默认情况下，数据被读取后，数据库系统立即解除共享锁。如果数据资源上放置了共享锁，还能再放置共享锁和更新锁。

排他锁：当一个事务执行insert、update或delete语句时，数据库系统会自动对SQL语句操纵的数据资源使用排他锁。如果该数据资源已经有其他锁（任何锁）存在时，就无法对其再放置排他锁了。排他锁不能和其他锁兼容，如果数据资源上已经加了独占锁，就不能再放置其他的锁了。同样，如果数据资源上已经放置了其他锁，那么也就不能再放置排他锁了。

更新锁：更新锁在的初始化阶段用来锁定可能要被修改的资源，这可以避免使用共享锁造成的死锁现象。更新锁与共享锁是兼容的，也就是说，一个资源可以同时放置更新锁和共享锁，但是最多放置一把更新锁。这样，当多个事务更新相同的数据时，只有一个事务能获得更新锁，然后再把更新锁升级为独占锁，其他事务必须等到前一个事务结束后，才能获取得更新锁，这就避免了死锁。

## 数据库事务

数据库事务(Database Transaction) ，是指作为单个逻辑工作单元执行的一系列操作，要么完全地执行，要么完全地不执行。

### 事务特性

- 原子性（**A**tomicity）: 事务`要么全部完成，要么全部取消`。 如果事务崩溃，状态回到事务之前（事务回滚）。
- 一致性（**C**onsistency）: 只有合法的数据（依照关系约束和函数约束）才能写入数据库。
- 隔离性（**I**solation）: 如果2个事务 T1 和 T2 同时运行，事务 T1 和 T2 最终的结果是相同的，不管 T1和T2谁先结束。
- 持久性（**D**urability）: 一旦事务提交，不管发生什么（崩溃或者出错），数据要保存在数据库中。

### 事务隔离级别

Read Uncommitted未提交读：读写均不使用锁，数据的一致性最差，也会出现许多逻辑错误

Read Committed提交读：使用写锁，但是读会出现不一致，不可重复读

Repeatable Read可重复读：使用读锁和写锁，解决不可重复读的问题，但会有幻读

Serializable可串行化：使用事务串形化调度，避免出现因为插入数据没法加锁导致的不一致的情况

### MVCC

MVCC是一种多版本并发控制机制。大多数的MySQL事务型存储引擎，如InnoDB都不止使用简单的行加锁机制，都和MVCC-多版本并发控制一起使用，锁机制可以控制并发操作,但是其系统开销较大,而MVCC可以在大多数情况下代替行级锁,使用MVCC,能降低其系统开销

MVCC实现原理主要是依赖记录中的 `四个隐式字段`、`undo日志` 、`Consistent Read View`来实现的。

在执行事务的每条SQL时，会先将数据原值写入undo log 中， 然后执行SQL对数据进行修改，最后将修改后的值写入redo log中。redo log 重做日志包括两部分：1 是内存中的重做日志缓冲 ；2 是重做日志文件。在事务提交时，必须先将该事务的所有日志写入到重做日志文件进行持久化，待事务commit操作完成才算完成。当一个事务中的所有SQL都执行成功后，会将redo log 缓存中的数据刷入磁盘，然后提交。如果发生回滚，会根据undo log 恢复数据。

MySQL InnoDB引擎ACID属性

- redo log重做日志用来保证事务的持久性
- undo log回滚日志保证事务的原子性
- undo log+redo log保证事务的一致性
- 锁（共享、排他）用来保证事务的隔离性

