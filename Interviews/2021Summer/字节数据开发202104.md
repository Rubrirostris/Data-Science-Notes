## 一面

1.自我介绍

2.介绍一个项目

3.数据处理流程

4.Spark基础知识

Spark的运行模式：

- 本地模式：Spark单机运行，一般用于开发测试。
- Standalone模式：构建一个由Master+Slave构成的Spark集群，Spark运行在集群中。
- Spark on Yarn模式：Spark客户端直接连接Yarn。不需要额外构建Spark集群。
- Spark on Mesos模式：Spark客户端直接连接Mesos。不需要额外构建Spark集群。

Spark的部署模式：

- Client模式：driver在client启动，做好准备工作，计划好任务的策略和方式（DAGScheduler)后向Master注册并申请运行Executor资源
- Cluster模式：Master调度应用，指定一个worker节点启动driver，即Scheduler-Backend

Spark-submit的参数：

-master: 指定运行模式，spark://host:port, mesos://host:port, yarn, or local[n]
-deploy-mode: 指定将driver端运行在client 还是在cluster
-class: 指定运行程序main方法类名，一般是应用程序的包名+类名
-name: 运用程序名称
-jars: 需要在driver端和executor端运行的jar,如mysql驱动包
-packages: maven管理的项目坐标GAV，多个以逗号分隔
-conf: 以key=value的形式传入sparkconf参数，所传入的参数必须是以spark.开头
-properties-file: 指定新的conf文件，默认使用spark-default.conf
-driver-memory:指定driver端运行内存，默认1G
-driver-cores：指定driver端cpu数量，默认1，仅在Standalone和Yarn的cluster模式下
-executor-memory：指定executor端的内存，默认1G
-total-executor-cores：所有executor使用的cores
-executor-cores: 每个executor使用的cores
-driver-class-path: driver端的classpath
-executor-class-path:executor端的classpath

spark宽依赖窄依赖的区别:

**窄依赖：**父RDD和子RDDpartition之间的关系是一对一的，或者父RDD一个partition只对应一个子RDD的partition情况下的父RDD和子RDD partition关系是多对一的，**不会有shuffle产生。**父RDD的一个分区去到了子RDD的一个分区

**宽依赖：**父RDD与子RDD partition之间的关系是一对多，**会有shuffle的产生**。父RDD的一个分区的数据去到了子RDD的不同分区里面。

![img](https://pic2.zhimg.com/80/v2-92a6e538e69e3ef92aca7278288ff541_1440w.jpg)

5.sql查询

查询一年内每个月的购买额大于一万的用户ID

聚集函数也叫列函数，它们都是基于整列数据进行计算的，而where子句则是对数据行进行过滤的，在筛选过程中依赖“基于已经筛选完毕的数据得出的计算结果”是一种悖论，这是行不通的。更简单地说，因为聚集函数要对全列数据时行计算，因而使用它的前提是：结果集已经确定，而where子句还处于“确定”结果集的过程中，因而不能使用聚集函数。

6.算法题top 2问题

第一种解法：堆排序

第二种解法：一次扫描

7.问题

什么部门？

数据中台，A/B test实验平台，主要做流失数据处理等

什么技术栈？

Hive Spark SQL Python Java

## 二面

1.自我介绍

2.两道SQL

怎么用SQL计算比率

3.算法题找数组中第一个不重复的字符

## 三面

1.自我介绍

2.大数据框架的知识

Kafka你了解吗

3.一道SQL子查询

用了join的方法，效率不是最高的

用子查询的方法先筛选出不符合题目要求的集合，再剔除

4.算法题：递归合并字典

