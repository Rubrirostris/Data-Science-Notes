## 蒙特卡洛方法

### 1.蒙特卡洛的概念

蒙特卡洛原来是一个赌场的名称，用它作为名字大概是因为蒙特卡洛方法是一种随机模拟的方法，这很像赌博场里面的扔骰子的过程。最早的蒙特卡洛方法都是为了求解一些不太好求解的求和或者积分问题

例如下图是一个经典的用蒙特卡洛求圆周率的问题，用计算机在一个正方形之中随机的生成点，计数有多少点落在1/4圆之中，这些点的数目除以总的点数目即圆的面积，根据圆面积公式即可求得圆周率

![img](https://i.loli.net/2021/08/04/19uzTpyRcW6Urwo.jpg)

蒙特卡洛算法的另一个应用是求积分，某些函数的积分不好求，我们可以按照下面的方法将这个函数进行分解，之后转化为求期望与求均值的问题

![[公式]](https://www.zhihu.com/equation?tex=%5Cint+_a%5Eb+h%28x%29dx%3D%5Cint+_a%5Ebf%28x%29p%28x%29dx%3DE_%7Bp%28x%29%7D%5Bf%28x%29%5D)

从分布 ![[公式]](https://www.zhihu.com/equation?tex=p%28x%29) 采样大量样本点 ![[公式]](https://www.zhihu.com/equation?tex=x_1%2Cx_2...x_n) ，这些样本符合分布 ![[公式]](https://www.zhihu.com/equation?tex=p%28x%29)

![[公式]](https://www.zhihu.com/equation?tex=E_%7Bp%28x%29%7D%5Bf%28x%29%5D%3D%5Cfrac%7B1%7D%7Bn%7D%5Csum+f%28x_i%29)

最终使用蒙特卡洛的方法求得积分

### 2.蒙特卡洛采样方法

对某一种概率分布p(x)进行蒙特卡洛采样的方法主要分为直接采样、拒绝采样与重要性采样三种，下面分别予以介绍

#### 2.1 直接采样

直接采样的方法是根据概率分布进行采样。对一个已知概率密度函数与累积概率密度函数的概率分布，我们可以直接从累积分布函数（cdf）进行采样

如下图所示是高斯分布的累积概率分布函数，可以看出函数的值域是(0, 1)，我们可以从U(0, 1)均匀分布中进行采样，再根据累积分布函数的反函数计算对应的x，这样就获得了符合高斯分布的N个粒子

![img](https://i.loli.net/2021/08/04/3C8HtGVP49NwM5E.jpg)

使用累积分布函数进行采样看似简单，但是由于很多分布我们并不能写出概率密度函数与累积分布函数，所以这种方法的适用范围较窄

#### 2.2 接受-拒绝采样

对于累积分布函数未知的分布，我们可以采用接受-拒绝采样。如下图所示，p(z)是我们希望采样的分布，q(z)是我们提议的分布(proposal distribution)，令kq(z)>p(z)，我们首先在kq(z)中按照直接采样的方法采样粒子，接下来判断这个粒子落在途中什么区域，对于落在灰色区域的粒子予以拒绝，落在红线下的粒子接受，最终得到符合p(z)的N个粒子

![img](https://i.loli.net/2021/08/04/uwcBUFMd2sDlvVO.jpg)

#### 2.3 重要性采样

接受拒绝采样完美的解决了累积分布函数不可求时的采样问题。但是接受拒绝采样非常依赖于提议分布(proposal distribution)的选择，如果提议分布选择的不好，可能采样时间很长却获得很少满足分布的粒子。而重要性采样就解决了这一问题

直接采样与接受拒绝采样都是假设每个粒子的权重相等，而重要性采样则是给予每个粒子不同的权重，使用加权平均的方法来计算期望

![[公式]](https://www.zhihu.com/equation?tex=E_%7Bp%28x%29%7D%5Bf%28x%29%5D%3D%5Cint+_a%5Ebf%28x%29%5Cfrac%7Bp%28x%29%7D%7Bq%28x%29%7Dq%28x%29dx%3DE_%7Bq%28x%29%7D%5Bf%28x%29%5Cfrac%7Bp%28x%29%7D%7Bq%28x%29%7D%5D)

我们从提议分布q(x)中采样大量粒子 ![[公式]](https://www.zhihu.com/equation?tex=x_1%2Cx_2...x_n) ，每个粒子的权重是 ![[公式]](https://www.zhihu.com/equation?tex=%5Cfrac%7Bp%28x_i%29%7D%7Bq%28x_i%29%7D) ，通过加权平均的方式可以计算出期望

![[公式]](https://www.zhihu.com/equation?tex=E_%7Bp%28x%29%7D%5Bf%28x%29%5D%3D%5Cfrac%7B1%7D%7BN%7D%5Csum+f%28x_i%29%5Cfrac%7Bp%28x_i%29%7D%7Bq%28x_i%29%7D)

### 3. 总结

蒙特卡洛方法是一种近似推断的方法，通过采样大量粒子的方法来求解期望、均值、面积、积分等问题，蒙特卡洛对某一种分布的采样方法有直接采样、接受拒绝采样与重要性采样三种，直接采样最简单，但是需要已知累积分布的形式。接受拒绝采样与重要性采样适用于原分布未知的情况，这两种方法都是给出一个提议分布，不同的是接受拒绝采样对不满足原分布的粒子予以拒绝，而重要性采样则是给予每个粒子不同的权重，大家可以根据不同的场景使用这三种方法中的一种进行采样。

## 序列蒙特卡洛

### 1.序列估计问题

谈起序列蒙特卡洛，就不得不说状态空间模型，可以说序列蒙特卡洛就是为了解决状态空间模型的参数估计问题而生的

状态空间模型指的是一个系统的状态会随着时间发生改变，进而导致这个系统对外展现出的变量也就是观测变量会发生改变。这个系统的状态可以用状态变量表示，观测值可以用观测变量表示。状态变量记为 ![[公式]](https://www.zhihu.com/equation?tex=%5C%7Bx_%7B1%3At%7D%5C%7D)，观测变量记为![[公式]](https://www.zhihu.com/equation?tex=%5C%7By_%7B1%3At%7D%5C%7D)

通常我们对这个系统的问题主要有三个方面：

1. 后验概率估计： ![[公式]](https://www.zhihu.com/equation?tex=p%28x_%7B1%3At%7D%7Cy_%7B1%3At%7D%29)
2. 观测变量的边际似然： ![[公式]](https://www.zhihu.com/equation?tex=p%28y_%7B1%3At%7D%29)
3. 某些函数的期望： ![[公式]](https://www.zhihu.com/equation?tex=E_%7Bp%28x%29%7D%5Bg%28x_%7B1%3At%7D%29%5D)

### 2.采样

#### 2.1 序列重要性采样

在上一篇文章中我们讲过，重要性采样给予每个粒子不同的权重，通过加权的方法算出期望、面积等问题

对于状态空间模型，粒子采样的方法通常选用序列重要性采样。采样过程首先从提议分布里对t时刻的变量进行采样，接下来通过上一代的粒子权重与本次计算出的粒子权重相乘计算出序列的权重

提议分布：

![[公式]](https://www.zhihu.com/equation?tex=q_%7Bn-1%7D+%28x_%7B1%3An%7D+%29%3Dq_%7Bn-1%7D+%28x_%7B1%3An-1%7D+%29+q_n+%28x_n+%7Cx_%7B1%3An-1%7D%29)

粒子权重：

![[公式]](https://www.zhihu.com/equation?tex=w_n+%28x_%7B1%3An%7D+%29%3D%5Cfrac%7Bp_n+%28x_%7B1%3An%7D%29%7D%7Bq_n+%28x_%7B1%3An%7D%29%7D%3D%5Cfrac%7Bp_%7Bn-1%7D%28x_%7B1%3An-1%7D%29%7D%7Bq_%7Bn-1%7D+%28x_%7B1%3An-1%7D%29%7D%5Cfrac%7Bp_n+%28x_%7B1%3An%7D%29%7D%7Bp_%7Bn-1%7D+%28x_%7B1%3An-1%7D+%29+q_n+%28x_n+%7Cx_%7B1%3An-1%7D%29%7D+)

![[公式]](https://www.zhihu.com/equation?tex=w_n+%28x_%7B1%3An%7D+%29%3Dw_%7Bn-1%7D+%28x_%7B1%3An-1%7D+%29%E2%88%97%CE%B1%28x_%7B1%3An%7D%29)

#### 2.2 缺点

序列重要性采样可以计算出对应一整个时间序列的粒子权重，但是这种采样方法可能导致部分粒子序列权重小，而只有少数粒子序列的权重大。从长期来看，这种方法计算出的期望和面积等不稳定，因此我们需要引入重采样机制。

### 3. 重采样

重采样机制是指对于权重较大的粒子序列进行复制，对于权重较小的粒子序列进行抛弃，通过重采样后，我们获得N个权重相等的粒子序列。通过重采样，我们可以避免之前重要性采样中由于权重迭代次数过多导致部分粒子权重很小，部分粒子权重很大的问题。重采样方法主要有系统重采样、残差重采样、多项式重采样等。为了减少计算量我们同时还引入了自适应重采样机制

如下图所示是一个重采样的粒子，计算出权重后，对于权重大的粒子予以保留同时复制，抛弃权重小的粒子，用新得到的粒子来拟合分布

![img](https://i.loli.net/2021/08/04/tfUxvCmi5bdlByI.jpg)

#### 3.1 系统重采样

如下图所示是系统重采样方法，将(0, 1)区间均匀分成N份，并将所有粒子按照权重依次进行累加，对于累加后跨过n个区间分界点的粒子复制n份，对于跨过0个区间分类点的粒子抛弃，系统重采样步骤如下

1.在均匀分布 ![[公式]](https://www.zhihu.com/equation?tex=U%280%2C++1%2FN%29) 中采样 ![[公式]](https://www.zhihu.com/equation?tex=U_0)

2.按照公式 ![[公式]](https://www.zhihu.com/equation?tex=U_i+%3D+U_0%2B%5Cfrac%7B%28i-1%29%7D%7BN%7D) 计算N个分界点

3.计算每个粒子采样次数

![[公式]](https://www.zhihu.com/equation?tex=N_i%3D%7B%E2%88%91_%7Bk%3D1%7D%5E%7Bi-1%7Dw_k%E2%89%A4U_i%E2%89%A4+%E2%88%91_%7Bk%3D1%7D%5Eiw_k+%7D)

#### 3.2 多项式重采样

另一种常用的方法是多项式重采样，多项式重采样算法首先利用重采样之前的粒子权值集合组成一个多项式分布即 ![[公式]](https://www.zhihu.com/equation?tex=Mult%28N%3Bw_k%281%29%2Cw_k%282%29%2C...%2Cw_k%28N%29%29) ，并从该多项式分布中抽样N次得到N个序号（其中每个序号取值为0-N之间的整数)， 然后，对应序号的粒子复制到一个新粒子集合中，该新粒子集合就是重采样后得到的粒子集合。

#### 3.3 自适应重采样

在序列重要性采样中，我们引入重采样机制是为了解决粒子权重退化的问题，但是目前我们使用的方法是在每一代都进行重采样，这种重采样方法时间复杂度比较高，我们希望能够缩减重采样的次数，只在必要时进行重采样，这就是自适应重采样的思想。自适应重采样需要实现规定一个有效粒子的阈值，例如采样N个粒子，规定有效粒子大于Neff时不进行重采样，小于Neff时通过系统重采样等方法进行重采样。这个阈值通常根据研究问题所选定。

### 4.采样步骤

t=0时刻：

初始化得到N个粒子 ![[公式]](https://www.zhihu.com/equation?tex=x_0)

计算 ![[公式]](https://www.zhihu.com/equation?tex=x_0) 对应的权重 ![[公式]](https://www.zhihu.com/equation?tex=w%28x_0%29)

根据权重 ![[公式]](https://www.zhihu.com/equation?tex=w%28x_0%29) 进行重采样

获得N个权重相等的粒子

t>0时刻：

从提议分布 ![[公式]](https://www.zhihu.com/equation?tex=q%28x_t+%7Cx_%7B1%3At-1%7D%29) 中进行采样

计算 ![[公式]](https://www.zhihu.com/equation?tex=x_t) 对应的权重 ![[公式]](https://www.zhihu.com/equation?tex=w%28x_t%29)

根据权重 ![[公式]](https://www.zhihu.com/equation?tex=w%28x_t%29) 进行重采样

获得N个权重相等的粒子

## 马尔可夫链蒙特卡洛

### 1.马尔可夫链

首先我们来简单介绍一下什么是马尔可夫链。如下图所示描述了一个马尔可夫链。对于股票市场而言有三种状态，分别是牛市、熊市和普通状态，这三种状态可以相互转化，且每个状态转移到另一个状态可以用一个条件概率的形式所表述，并且每个时刻的状态只依赖于它上一时刻的状态，这种性质称为一阶马尔可夫性质。

![img](https://i.loli.net/2021/08/04/XAB4VNKtebZkizx.png)

对于部分马尔可夫链有一种好的属性，这种属性是无论系统状态的初值如何取，经过有限次状态转移，最终的终点状态都是相同的，这种马尔可夫链称为平稳的马尔可夫链，而最终得到的分布称为马尔可夫链的平稳分布。

当然平稳的马尔可夫链存在一些条件，这个条件称为细致平稳条件(Detailed Balance)。如下面这个等式所描述的，对于一个分布 ![[公式]](https://www.zhihu.com/equation?tex=+%5Cpi%28x%29) ，如果能找到相应的矩阵P，满足下列性质，则这个分布属于状态转移矩阵P的平稳分布。

![[公式]](https://www.zhihu.com/equation?tex=%5Cpi%28i%29P%28i%2Cj%29+%3D+%5Cpi%28j%29P%28j%2Ci%29)

### 2.采样

#### 2.1 MCMC采样

上面我们已经介绍了平稳分布的概念以及平稳分布对应的状态转移矩阵，现在的问题就是如何找到状态转移矩阵P，我们从概念出发可以得到基础的MCMC采样方法。

一般情况下，对于一个分布 ![[公式]](https://www.zhihu.com/equation?tex=%5Cpi%28x%29) ，我们任意取的状态转移矩阵Q不满足细致平稳条件

![[公式]](https://www.zhihu.com/equation?tex=%5Cpi%28i%29Q%28i%2C+j%29%5Cne%5Cpi%28j%29Q%28j%2Ci%29)

我们给不等式两边同乘 ![[公式]](https://www.zhihu.com/equation?tex=%5Calpha) ，使得等式成立，其中 ![[公式]](https://www.zhihu.com/equation?tex=%5Calpha) 满足下列性质

![[公式]](https://www.zhihu.com/equation?tex=%5Cpi%28i%29Q%28i%2C+j%29%5Calpha%28i%2Cj%29%3D%5Cpi%28j%29Q%28j%2Ci%29%5Calpha%28j%2Ci%29)

![[公式]](https://www.zhihu.com/equation?tex=%5Calpha%28i%2Cj%29%3D%5Cpi%28j%29Q%28j%2Ci%29)

![[公式]](https://www.zhihu.com/equation?tex=%5Calpha%28j%2Ci%29%3D%5Cpi%28i%29Q%28i%2Cj%29)

下面是我们的采样过程：

输入我们任意选定的马尔科夫链状态转移矩阵 ![[公式]](https://www.zhihu.com/equation?tex=Q) ，平稳分布 ![[公式]](https://www.zhihu.com/equation?tex=%5Cpi%28x%29)

从任意简单概率分布采样得到初始状态值 ![[公式]](https://www.zhihu.com/equation?tex=x_0)

for t = 1:T

从条件概率分布 ![[公式]](https://www.zhihu.com/equation?tex=Q%28x%7Cx_t%29) 中采样得到样本 ![[公式]](https://www.zhihu.com/equation?tex=x%E2%88%97)

从均匀分布采样 ![[公式]](https://www.zhihu.com/equation?tex=u%5Csim+uniform%5B0%2C1%5D)

如果 ![[公式]](https://www.zhihu.com/equation?tex=u%3C%5Calpha%28x_t%2Cx%2A%29%3D%5Cpi%28x%2A%29Q%28x%2A%2Cx_t%29) , 则接受转移 ![[公式]](https://www.zhihu.com/equation?tex=x_t-x%2A) ，即 ![[公式]](https://www.zhihu.com/equation?tex=x_%7Bt%2B1%7D%3Dx%E2%88%97)

否则不接受转移，即 ![[公式]](https://www.zhihu.com/equation?tex=x_%7Bt%2B1%7D%3Dx_t)

从t时刻开始为平稳分布，样本集 ![[公式]](https://www.zhihu.com/equation?tex=%28x_t%2Cx_%7Bt%2B1%7D%2C...%2Cx_T%29) 即为我们需要的平稳分布对应的样本集

#### 2.2 M-H采样

MCMC采样看似简单，但是由于 ![[公式]](https://www.zhihu.com/equation?tex=%5Calpha) 取值过小，接受率过低，迭代较长时间无法得到平稳分布，而M-H在MCMC采样的基础上做出了一些改进。M-H采样的思想是如果给上面细致平稳条件等式两边同时乘一个数，细致平稳条件依然满足。如下所示，我们对接受率进行了一定改进。

![[公式]](https://www.zhihu.com/equation?tex=%5Calpha%28i%2Cj%29%3Dmin%28%5Cfrac%7B%5Cpi%28j%29Q%28j%2Ci%29%7D%7B%5Cpi%28i%29Q%28i%2Cj%29%7D%2C1%29)

下面是M-H采样的步骤：

输入我们任意选定的马尔科夫链状态转移矩阵 ![[公式]](https://www.zhihu.com/equation?tex=Q) ，平稳分布 ![[公式]](https://www.zhihu.com/equation?tex=%5Cpi%28x%29)

从任意简单概率分布采样得到初始状态值 ![[公式]](https://www.zhihu.com/equation?tex=x_0)

for t = 1:T

从条件概率分布 ![[公式]](https://www.zhihu.com/equation?tex=Q%28x%7Cx_t%29) 中采样得到样本 ![[公式]](https://www.zhihu.com/equation?tex=x%2A)

从均匀分布采样 ![[公式]](https://www.zhihu.com/equation?tex=u%5Csim+uniform%5B0%2C1%5D)

如果 ![[公式]](https://www.zhihu.com/equation?tex=u%3C%5Calpha%28x_t%2Cx%2A%29%3Dmin%28%5Cfrac%7B%5Cpi%28j%29Q%28j%2Ci%29%7D%7B%5Cpi%28i%29Q%28i%2Cj%29%7D%2C1%29) , 则接受转移，否则不接受转移

从t时刻开始为平稳分布，样本集 ![[公式]](https://www.zhihu.com/equation?tex=%28x_t%2Cx_%7Bt%2B1%7D%2C...%2Cx_T%29) 即为我们需要的平稳分布对应的样本集

#### 2.3 Gibbs采样

虽然M-H在一定程度上解决了MCMC采样接受率过低的问题，但是对于大数据集，上面计算接受率的过程复杂度较高，整个算法的运行效率不高，而Gibbs采样就解决了这一问题。

对于二维数据，下列两式成立

![[公式]](https://www.zhihu.com/equation?tex=%5Cpi%28x_1%5E1%2Cx_1%5E2%29%5Cpi%28x_2%5E2%7Cx_1%5E1%29%3D%5Cpi%28x_1%5E1%29%5Cpi%28x_1%5E2%7Cx_1%5E1%29%5Cpi%28x_2%5E2%7Cx_1%5E1%29)

![[公式]](https://www.zhihu.com/equation?tex=%5Cpi%28x_1%5E1%2Cx_2%5E2%29%5Cpi%28x_1%5E2%7Cx_1%5E1%29%3D%5Cpi%28x_1%5E1%29%5Cpi%28x_2%5E2%7Cx_1%5E1%29%5Cpi%28x_1%5E2%7Cx_1%5E1%29)

由此推知：

![[公式]](https://www.zhihu.com/equation?tex=%5Cpi%28x_1%5E1%2Cx_1%5E2%29%5Cpi%28x_2%5E2%7Cx_1%5E1%29%3D%5Cpi%28x_1%5E1%2Cx_2%5E2%29%5Cpi%28x_1%5E2%7Cx_1%5E1%29)

在 ![[公式]](https://www.zhihu.com/equation?tex=+_1%3D+_1%5E1) 这条直线上，如果用条件概率分布 ![[公式]](https://www.zhihu.com/equation?tex=+%28+_2%7C+_1%5E1%29) 作为马尔科夫链的状态转移概率，则任意两个点之间的转移满足细致平稳条件。同理，在在 ![[公式]](https://www.zhihu.com/equation?tex=+_2%3D+_1%5E2) 这条直线上，如果用条件概率分布 ![[公式]](https://www.zhihu.com/equation?tex=+%28+_1%7C+_1%5E2%29) 作为马尔科夫链的状态转移概率，则任意两个点之间的转移也满足细致平稳条件

对平面上的任意两点，有下列性质

![[公式]](https://www.zhihu.com/equation?tex=%5Cpi%28A%29P%28A-%3EB%29%3D%5Cpi%28B%29P%28B-%3EA%29)

Gibbs采样过程如下：

输入平稳分布 ![[公式]](https://www.zhihu.com/equation?tex=%5Cpi%28x_1%2Cx_2%EF%BC%8C...%2Cx_+%29) 或者对应的所有特征的条件概率分布

随机初始化初始状态值 ![[公式]](https://www.zhihu.com/equation?tex=%28x%5E0_1%2Cx%5E0_2%2C...%2Cx%5E0_n%29)

for =1:T

从条件概率分布 ![[公式]](https://www.zhihu.com/equation?tex=P%28x_1%7Cx%5Et_2%2Cx%5Et_3%2C...%2Cx%5Et_n%29) 中采样得到样本 ![[公式]](https://www.zhihu.com/equation?tex=x%5E%7Bt%2B1%7D_1)

从条件概率分布 ![[公式]](https://www.zhihu.com/equation?tex=P%28x_j%7Cx%5E%7Bt%2B1%7D_1%2Cx%5E%7Bt%2B1%7D_2%2C...%2Cx%5E%7Bt%2B1%7D_%7Bj-1%7D%2Cx%5E%7Bt%7D_%7Bj%2B1%7D...%2Cx%5E%7Bt%7D_n%29) 中采样得到样本 ![[公式]](https://www.zhihu.com/equation?tex=x%5E%7Bt%2B1%7D_j)

从条件概率分布 ![[公式]](https://www.zhihu.com/equation?tex=P%28x_n%7Cx%5E%7Bt%2B1%7D_1%2Cx%5E%7Bt%2B1%7D_2%2C...%2Cx%5E%7Bt%2B1%7D_%7Bn%E2%88%921%7D%29) 中采样得到样本 ![[公式]](https://www.zhihu.com/equation?tex=x%5E%7Bt%2B1%7D_n)

从t时刻开始为平稳分布，样本集 ![[公式]](https://www.zhihu.com/equation?tex=%28x_t%2Cx_%7Bt%2B1%7D%2C...%2Cx_T%29) 即为我们需要的平稳分布对应的样本集

Gibbs采样类似于坐标下降法，固定n-1个特征，对某个特征进行采样，下图表示了二维数据的采样过程。

![img](https://i.loli.net/2021/08/04/oDpU9tCwaEN4Gq1.png)